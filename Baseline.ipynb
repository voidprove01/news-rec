{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d96fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import time, math, os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e89f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data_raw/'\n",
    "save_path = './tmp_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e145e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reduce memory\n",
    "def reduce_mem(df):\n",
    "    starttime = time.time()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n",
    "                                                                                                           100*(start_mem-end_mem)/start_mem,\n",
    "                                                                                                           (time.time()-starttime)/60))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec11d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug mode\n",
    "def get_all_click_sample(data_path, sample_nums=10000):\n",
    "    \"\"\"\n",
    "        sampling a portion from trainng test to debug\n",
    "        sample_nums: number of samples\n",
    "    \"\"\"\n",
    "    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    all_user_ids = all_click.user_id.unique()\n",
    "\n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False) \n",
    "    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe18129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read click data\n",
    "def get_all_click_df(data_path='./data_raw/', offline=True):\n",
    "    if offline:\n",
    "        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    else:\n",
    "        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "\n",
    "        all_click = pd.concat([trn_click, tst_click], ignore_index=True)\n",
    "\n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82fd3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole dataset\n",
    "all_click_df = get_all_click_df(offline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30e25023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0         199999            160417    1507029570190                  4   \n",
       "1         199999              5408    1507029571478                  4   \n",
       "2         199999             50823    1507029601478                  4   \n",
       "3         199998            157770    1507029532200                  4   \n",
       "4         199998             96613    1507029671831                  4   \n",
       "...          ...               ...              ...                ...   \n",
       "1630628   221924             70758    1508211323220                  4   \n",
       "1630629   207823            331116    1508211542618                  4   \n",
       "1630630   207823            234481    1508211850103                  4   \n",
       "1630631   207823            211442    1508212189949                  4   \n",
       "1630632   207823            211401    1508212315718                  4   \n",
       "\n",
       "         click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                        1        17              1            13   \n",
       "1                        1        17              1            13   \n",
       "2                        1        17              1            13   \n",
       "3                        1        17              1            25   \n",
       "4                        1        17              1            25   \n",
       "...                    ...       ...            ...           ...   \n",
       "1630628                  3         2              1            25   \n",
       "1630629                  3         2              1            25   \n",
       "1630630                  3         2              1            25   \n",
       "1630631                  3         2              1            25   \n",
       "1630632                  3         2              1            25   \n",
       "\n",
       "         click_referrer_type  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          5  \n",
       "4                          5  \n",
       "...                      ...  \n",
       "1630628                    2  \n",
       "1630629                    1  \n",
       "1630630                    1  \n",
       "1630631                    1  \n",
       "1630632                    1  \n",
       "\n",
       "[1630633 rows x 9 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c701a",
   "metadata": {},
   "source": [
    "# Getting user-item-click_time dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6f7bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    {user1: {item1: time1, item2: time2..}...}\n",
    "def get_user_item_time(click_df):\n",
    "    # Sort the DataFrame by timestamp to maintain chronological order\n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    \n",
    "    # Group by 'user_id' and aggregate the columns into a list of tuples\n",
    "    user_item_time_df = (\n",
    "        click_df.groupby('user_id')[['click_article_id', 'click_timestamp']]\n",
    "        .apply(lambda x: list(zip(x['click_article_id'], x['click_timestamp'])))\n",
    "        .reset_index(name='item_time_list')\n",
    "    )\n",
    "    \n",
    "    # Create a dictionary with 'user_id' as keys and 'item_time_list' as values\n",
    "    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    \n",
    "    return user_item_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c77809",
   "metadata": {},
   "source": [
    "# Getting top k articles with largest nunmber of clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268b4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_topk_click(click_df, k):\n",
    "    topk_click = click_df['click_article_id'].value_counts().index[:k]\n",
    "    return topk_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167fddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4443704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemcf_sim(df):\n",
    "    \"\"\"\n",
    "        compute item to item similarity matrix\n",
    "        :param df: df\n",
    "        :item_created_time_dict:  dict contains article creat time\n",
    "        return : similarity matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    user_item_time_dict = get_user_item_time(df)\n",
    "    \n",
    "    i2i_sim = {}\n",
    "    item_cnt = defaultdict(int)\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        # temporal considerations\n",
    "        for i, i_click_time in item_time_list:\n",
    "            item_cnt[i] += 1\n",
    "            i2i_sim.setdefault(i, {})\n",
    "            for j, j_click_time in item_time_list:\n",
    "                if(i == j):\n",
    "                    continue\n",
    "                i2i_sim[i].setdefault(j, 0)\n",
    "                \n",
    "                i2i_sim[i][j] += 1 / math.log(len(item_time_list) + 1)\n",
    "                \n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "    \n",
    "    pickle.dump(i2i_sim_, open(save_path + 'itemcf_i2i_sim.pkl', 'wb'))\n",
    "    \n",
    "    return i2i_sim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a01254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 250000/250000 [00:09<00:00, 25414.53it/s]\n"
     ]
    }
   ],
   "source": [
    "i2i_sim = itemcf_sim(all_click_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec04d30",
   "metadata": {},
   "source": [
    "# Recall by item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1179d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click):\n",
    "\n",
    "    \"\"\"\n",
    "        :param user_id: user id\n",
    "        :param user_item_time_dict:dict,   {user1: {item1: time1, item2: time2..}...}\n",
    "        :param i2i_sim: dict,，item similarity matrix\n",
    "        :param sim_item_topk: int，top k articles closed to the current one\n",
    "        :param recall_item_num: int， number of recalled articles\n",
    "        :param item_topk_click: list，articules with top k numbe of clicks       \n",
    "        return: list {item1:score1, item2: score2...}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # list of items in user's browsing history\n",
    "    user_hist_items = user_item_time_dict[user_id]\n",
    "    \n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items):\n",
    "        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n",
    "            if j in user_hist_items:\n",
    "                continue\n",
    "                \n",
    "            item_rank.setdefault(j, 0)\n",
    "            item_rank[j] +=  wij\n",
    "    \n",
    "    # the gap is filled with popular items (item_topk_click) that are not already present in item_rank\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank.items(): \n",
    "                continue\n",
    "            item_rank[item] = - i - 100 # any negative number\n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break\n",
    "    \n",
    "    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n",
    "        \n",
    "    return item_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa89b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c20e3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 250000/250000 [19:10<00:00, 217.36it/s]\n"
     ]
    }
   ],
   "source": [
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "\n",
    "# load dict\n",
    "user_item_time_dict = get_user_item_time(all_click_df)\n",
    "\n",
    "# load item to item similarity\n",
    "i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\n",
    "\n",
    "# number of similar items\n",
    "sim_item_topk = 10\n",
    "\n",
    "# number of recalled items\n",
    "recall_item_num = 10\n",
    "\n",
    "# filling with popular items\n",
    "item_topk_click = get_item_topk_click(all_click_df, k=50)\n",
    "\n",
    "for user in tqdm(all_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, \n",
    "                                                        sim_item_topk, recall_item_num, item_topk_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "608f650d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 250000/250000 [00:03<00:00, 82882.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert dict to df\n",
    "user_item_score_list = []\n",
    "\n",
    "for user, items in tqdm(user_recall_items_dict.items()):\n",
    "    for item, score in items:\n",
    "        user_item_score_list.append([user, item, score])\n",
    "\n",
    "recall_df = pd.DataFrame(user_item_score_list, columns=['user_id', 'click_article_id', 'pred_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c89fbc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate file for submission\n",
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6306dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "tst_users = tst_click['user_id'].unique()\n",
    "\n",
    "\n",
    "tst_recall = recall_df[recall_df['user_id'].isin(tst_users)]\n",
    "\n",
    "# generate file for submission\n",
    "submit(tst_recall, topk=5, model_name='itemcf_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31841d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
